{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2660420a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    Ridge,\n",
    "    Lasso,\n",
    "    SGDRegressor\n",
    "    )\n",
    "from sklearn.tree import (\n",
    "    DecisionTreeRegressor\n",
    ")\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    BaggingRegressor\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold\n",
    ")\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost.callback import EarlyStopping\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b1e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading datasets\n",
    "first_batch  = np.load(\"data/Week1/first_batch_regression_labelled.npz\")\n",
    "second_batch  = np.load(\"data/Week2/second_batch_regression_labelled.npz\")\n",
    "third_batch  = np.load(\"data/Week3/third_batch_regression_labelled.npz\")\n",
    "fourth_batch  = np.load(\"data/Week4/fourth_batch_regression_labelled.npz\")\n",
    "\n",
    "# Extract X, y, y_cat for each batch\n",
    "X1, y1, y1_cat = first_batch[\"X\"], first_batch[\"yy\"], first_batch[\"yy_cat\"]\n",
    "X2, y2, y2_cat = second_batch[\"X\"], second_batch[\"yy\"], second_batch[\"yy_cat\"]\n",
    "X3, y3, y3_cat = third_batch[\"X\"], third_batch[\"yy\"], third_batch[\"yy_cat\"]\n",
    "X4, y4, y4_cat = fourth_batch[\"X\"], fourth_batch[\"yy\"], fourth_batch[\"yy_cat\"]\n",
    "\n",
    "# Convert to DataFrames and rename columns for each batch\n",
    "X1     = pd.DataFrame(X1, columns=[\"user\", \"item\", \"rating\"])\n",
    "y1     = pd.DataFrame(y1, columns=[\"user\", \"label\"])\n",
    "y1_cat = pd.DataFrame(y1_cat, columns=[\"user\", \"label\", \"anomtype\"])\n",
    "X2     = pd.DataFrame(X2, columns=[\"user\", \"item\", \"rating\"])\n",
    "y2     = pd.DataFrame(y2, columns=[\"user\", \"label\"])\n",
    "y2_cat = pd.DataFrame(y2_cat, columns=[\"user\", \"label\", \"anomtype\"])\n",
    "X3     = pd.DataFrame(X3, columns=[\"user\", \"item\", \"rating\"])\n",
    "y3     = pd.DataFrame(y3, columns=[\"user\", \"label\"])\n",
    "y3_cat = pd.DataFrame(y3_cat, columns=[\"user\", \"label\", \"anomtype\"])\n",
    "X4     = pd.DataFrame(X4, columns=[\"user\", \"item\", \"rating\"])\n",
    "y4     = pd.DataFrame(y4, columns=[\"user\", \"label\"])\n",
    "y4_cat = pd.DataFrame(y4_cat, columns=[\"user\", \"label\", \"anomtype\"])\n",
    "\n",
    "# Combine the data \n",
    "X = pd.concat([X1, X2, X3, X4], ignore_index=True)\n",
    "y = pd.concat([y1, y2, y3, y4], ignore_index=True)\n",
    "y_cat = pd.concat([y1_cat, y2_cat, y3_cat, y4_cat], ignore_index=True)\n",
    "\n",
    "# Parse to correct types\n",
    "y     = y.astype({\"user\": int, \"label\": float})\n",
    "y_cat = y_cat.astype({\"user\": int, \"label\": float, \"anomtype\": int})\n",
    "\n",
    "# Latest test data\n",
    "XX    = np.load(\"data/Week4/fifth_batch_regression_unlabelled.npz\")['X']\n",
    "XX    = pd.DataFrame(XX, columns=[\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a808ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144737</th>\n",
       "      <td>3599</td>\n",
       "      <td>396</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144738</th>\n",
       "      <td>3599</td>\n",
       "      <td>183</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144739</th>\n",
       "      <td>3599</td>\n",
       "      <td>877</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144740</th>\n",
       "      <td>3599</td>\n",
       "      <td>961</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144741</th>\n",
       "      <td>3599</td>\n",
       "      <td>416</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1144742 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user  item  rating\n",
       "0           0    94       2\n",
       "1           0    90       1\n",
       "2           0    97       2\n",
       "3           0   100       4\n",
       "4           0   101       2\n",
       "...       ...   ...     ...\n",
       "1144737  3599   396       4\n",
       "1144738  3599   183       3\n",
       "1144739  3599   877       3\n",
       "1144740  3599   961       5\n",
       "1144741  3599   416       4\n",
       "\n",
       "[1144742 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking loads:\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6fa4532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.962817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.031248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.068668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.349012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.917704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>3595</td>\n",
       "      <td>0.720721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>3596</td>\n",
       "      <td>0.705247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>3597</td>\n",
       "      <td>0.362698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>3598</td>\n",
       "      <td>0.072459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>3599</td>\n",
       "      <td>0.891723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user     label\n",
       "0        0  0.962817\n",
       "1        1  0.031248\n",
       "2        2  0.068668\n",
       "3        3  0.349012\n",
       "4        4  0.917704\n",
       "...    ...       ...\n",
       "3595  3595  0.720721\n",
       "3596  3596  0.705247\n",
       "3597  3597  0.362698\n",
       "3598  3598  0.072459\n",
       "3599  3599  0.891723\n",
       "\n",
       "[3600 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking loads: (Pt. 2)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc76666b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking loads: (Pt. 3)\n",
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2aa71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600</td>\n",
       "      <td>849</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3600</td>\n",
       "      <td>722</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3600</td>\n",
       "      <td>462</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3600</td>\n",
       "      <td>982</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3600</td>\n",
       "      <td>749</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284949</th>\n",
       "      <td>4499</td>\n",
       "      <td>757</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284950</th>\n",
       "      <td>4499</td>\n",
       "      <td>752</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284951</th>\n",
       "      <td>4499</td>\n",
       "      <td>751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284952</th>\n",
       "      <td>4499</td>\n",
       "      <td>778</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284953</th>\n",
       "      <td>4499</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284954 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  item  rating\n",
       "0       3600   849       5\n",
       "1       3600   722       5\n",
       "2       3600   462       4\n",
       "3       3600   982       4\n",
       "4       3600   749       4\n",
       "...      ...   ...     ...\n",
       "284949  4499   757       4\n",
       "284950  4499   752       4\n",
       "284951  4499   751       4\n",
       "284952  4499   778       4\n",
       "284953  4499     3       3\n",
       "\n",
       "[284954 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking loads: (Pt. 4)\n",
    "XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dddafac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Explained by SVD: 0.9032\n",
      "(3600, 1000)\n",
      "(900, 1000)\n",
      "(3600, 650)\n",
      "(900, 650)\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicates\n",
    "X = X.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\")\n",
    "XX = XX.drop_duplicates(subset=[\"user\", \"item\"], keep=\"last\")\n",
    "\n",
    "# SVD for regression dataframe\n",
    "X_matrix = X.pivot(index=\"user\", columns=\"item\", values=\"rating\").fillna(0)\n",
    "XX_matrix = XX.pivot(index=\"user\", columns=\"item\", values=\"rating\").fillna(0)\n",
    "\n",
    "# SVD --- say WHATTTTTTTT\n",
    "svd = TruncatedSVD(n_components=650, random_state=42)\n",
    "X_svd = svd.fit_transform(X_matrix)\n",
    "XX_svd = svd.transform(XX_matrix)\n",
    "\n",
    "print(f\"Variance Explained by SVD: {svd.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "df_reg_train = pd.DataFrame(X_svd, index=X_matrix.index)\n",
    "df_reg_test = pd.DataFrame(XX_svd, index=XX_matrix.index)\n",
    "\n",
    "print(X_matrix.shape)\n",
    "print(XX_matrix.shape)\n",
    "print(df_reg_train.shape)\n",
    "print(df_reg_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be55dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bn/ddy389t944nd6glc1c0dtgzc0000gn/T/ipykernel_57177/1619606638.py:27: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  user_bias = X.groupby('user').apply(lambda df: (df['rating'] - df['item_mean']).mean()).rename('user_bias')\n",
      "/var/folders/bn/ddy389t944nd6glc1c0dtgzc0000gn/T/ipykernel_57177/1619606638.py:83: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  extreme_ratio = X.groupby('user').apply(lambda df: ((df['rating']==1)|(df['rating']==5)).mean()).rename('extreme_ratio')\n",
      "/var/folders/bn/ddy389t944nd6glc1c0dtgzc0000gn/T/ipykernel_57177/1619606638.py:130: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  extreme_ratio_test = XX.groupby('user').apply(lambda df: ((df['rating']==1)|(df['rating']==5)).mean()).rename('extreme_ratio')\n"
     ]
    }
   ],
   "source": [
    "# --- FEATURE ENGINEERING (This is mainly what I worked on, sry cause its super messy) ---\n",
    "\n",
    "# base user stats\n",
    "X_stats = X.groupby(\"user\").agg(\n",
    "    mean_rating=('rating', 'mean'),\n",
    "    std_rating=('rating', 'std'),\n",
    "    min_rating=('rating', 'min'),\n",
    "    max_rating=('rating', 'max'),\n",
    "    total_interactions=('rating', 'count')\n",
    ")\n",
    "X_stats['rating_var'] = X_stats['std_rating'] ** 2\n",
    "X_stats['normalized_std'] = X_stats['std_rating'] / (X_stats['mean_rating'] + 1e-5)\n",
    "X_stats['skewness'] = X.groupby('user')['rating'].skew()\n",
    "X_stats['kurtosis'] = X.groupby('user')['rating'].apply(pd.Series.kurt)\n",
    "X_stats = X_stats.fillna(0)\n",
    "\n",
    "# --- Extra stuff starts from here... ---\n",
    "# checking if ratings are biased by global mean per item\n",
    "global_mean = X['rating'].mean()\n",
    "\n",
    "# create and merge item-level means/stds BEFORE any references\n",
    "item_stats = X.groupby('item')['rating'].agg(['mean', 'std']).rename(columns={'mean': 'item_mean', 'std': 'item_std'})\n",
    "item_stats = item_stats.fillna(0)\n",
    "X = X.merge(item_stats, on='item', how='left')\n",
    "\n",
    "# user bias relative to item mean\n",
    "user_bias = X.groupby('user').apply(lambda df: (df['rating'] - df['item_mean']).mean()).rename('user_bias')\n",
    "X_stats = X_stats.merge(user_bias, on='user', how='left').fillna(0)\n",
    "\n",
    "# rating distribution (extremeties p much)\n",
    "rating_counts = X.groupby(['user', 'rating']).size().unstack(fill_value=0)\n",
    "rating_counts.columns = [f'rating_{int(c)}_count' for c in rating_counts.columns]\n",
    "X_stats = X_stats.merge(rating_counts, on='user', how='left').fillna(0)\n",
    "\n",
    "# proportion of total items rated\n",
    "num_items = X['item'].nunique()\n",
    "X_stats['interaction_ratio'] = X_stats['total_interactions'] / num_items\n",
    "\n",
    "# user outlier fraction (how often ratings deviate strongly from usual)\n",
    "X['abs_dev'] = abs(X['rating'] - X['item_mean'])\n",
    "user_outlier_frac = (X['abs_dev'] > 1.5 * X['item_std']).groupby(X['user']).mean().rename('outlier_frac')\n",
    "X_stats = X_stats.merge(user_outlier_frac, on='user', how='left').fillna(0)\n",
    "\n",
    "# item anomalies?? maybe the items have something weird going on there...\n",
    "item_stats_expanded = X.groupby(\"item\").agg(\n",
    "    item_mean=('rating', 'mean'),\n",
    "    item_std=('rating', 'std'),\n",
    "    item_var=('rating', lambda x: np.var(x, ddof=1)),\n",
    "    item_min=('rating', 'min'),\n",
    "    item_max=('rating', 'max'),\n",
    "    item_total=('rating', 'count')\n",
    ")\n",
    "item_stats_expanded['item_skew'] = X.groupby('item')['rating'].skew()\n",
    "item_stats_expanded['item_kurt'] = X.groupby('item')['rating'].apply(pd.Series.kurt)\n",
    "item_stats_expanded['item_range'] = item_stats_expanded['item_max'] - item_stats_expanded['item_min']\n",
    "item_stats_expanded['item_mean_rank'] = item_stats_expanded['item_mean'].rank(pct=True)\n",
    "item_stats_expanded = item_stats_expanded.fillna(0)\n",
    "\n",
    "# debug\n",
    "for col in ['item_mean', 'item_std', 'item_mean_x', 'item_mean_y', 'item_std_x', 'item_std_y']:\n",
    "    if col in X.columns:\n",
    "        X = X.drop(columns=col)\n",
    "\n",
    "X = X.merge(item_stats_expanded, on='item', how='left')\n",
    "\n",
    "X['item_mean'] = X['item_mean']\n",
    "X['item_std'] = X['item_std']\n",
    "\n",
    "# mooar extra\n",
    "X['deviation_from_item_mean'] = X['rating'] - X['item_mean']\n",
    "X['z_score_item'] = X['deviation_from_item_mean'] / (X['item_std'] + 1e-6)\n",
    "alignment_by_user = X.groupby('user')['z_score_item'].mean().rename('mean_item_alignment')\n",
    "X_stats = X_stats.merge(alignment_by_user, on='user', how='left').fillna(0)\n",
    "\n",
    "# entropy  woooooo\n",
    "from scipy.stats import entropy\n",
    "def rating_entropy(ratings):\n",
    "    counts = ratings.value_counts(normalize=True)\n",
    "    return entropy(counts)\n",
    "\n",
    "user_entropy = X.groupby('user')['rating'].apply(rating_entropy).rename('rating_entropy')\n",
    "extreme_ratio = X.groupby('user').apply(lambda df: ((df['rating']==1)|(df['rating']==5)).mean()).rename('extreme_ratio')\n",
    "X_stats = X_stats.merge(user_entropy, on='user', how='left').merge(extreme_ratio, on='user', how='left').fillna(0)\n",
    "\n",
    "# normalizing rank\n",
    "X_stats['user_mean_rank'] = X_stats['mean_rating'].rank(pct=True)\n",
    "\n",
    "# merge\n",
    "df_reg_train = df_reg_train.merge(X_stats, on='user', how='left')\n",
    "df_reg_train = df_reg_train.merge(y, on='user', how='inner')\n",
    "\n",
    "# --- same stuff for XX ---\n",
    "for col in ['item_mean', 'item_std', 'item_mean_x', 'item_mean_y', 'item_std_x', 'item_std_y']:\n",
    "    if col in XX.columns:\n",
    "        XX = XX.drop(columns=col)\n",
    "\n",
    "XX = XX.merge(item_stats_expanded, on='item', how='left')\n",
    "\n",
    "# debug\n",
    "XX['item_mean'] = XX['item_mean']\n",
    "XX['item_std'] = XX['item_std']\n",
    "\n",
    "XX_stats = XX.groupby(\"user\").agg(\n",
    "    mean_rating=('rating', 'mean'),\n",
    "    std_rating=('rating', 'std'),\n",
    "    min_rating=('rating', 'min'),\n",
    "    max_rating=('rating', 'max'),\n",
    "    total_interactions=('rating', 'count')\n",
    ")\n",
    "XX_stats['rating_var'] = XX_stats['std_rating'] ** 2\n",
    "XX_stats['normalized_std'] = XX_stats['std_rating'] / (XX_stats['mean_rating'] + 1e-5)\n",
    "XX_stats['skewness'] = XX.groupby('user')['rating'].skew()\n",
    "XX_stats['kurtosis'] = XX.groupby('user')['rating'].apply(pd.Series.kurt)\n",
    "XX_stats = XX_stats.fillna(0)\n",
    "\n",
    "num_items_test = XX['item'].nunique()\n",
    "XX_stats['interaction_ratio'] = XX_stats['total_interactions'] / num_items_test\n",
    "\n",
    "XX['abs_dev'] = abs(XX['rating'] - XX['item_mean'])\n",
    "user_outlier_frac_test = (XX['abs_dev'] > 1.5 * XX['item_std']).groupby(XX['user']).mean().rename('outlier_frac')\n",
    "XX_stats = XX_stats.merge(user_outlier_frac_test, on='user', how='left').fillna(0)\n",
    "\n",
    "XX['deviation_from_item_mean'] = XX['rating'] - XX['item_mean']\n",
    "XX['z_score_item'] = XX['deviation_from_item_mean'] / (XX['item_std'] + 1e-6)\n",
    "alignment_by_user_test = XX.groupby('user')['z_score_item'].mean().rename('mean_item_alignment')\n",
    "XX_stats = XX_stats.merge(alignment_by_user_test, on='user', how='left').fillna(0)\n",
    "\n",
    "user_entropy_test = XX.groupby('user')['rating'].apply(rating_entropy).rename('rating_entropy')\n",
    "extreme_ratio_test = XX.groupby('user').apply(lambda df: ((df['rating']==1)|(df['rating']==5)).mean()).rename('extreme_ratio')\n",
    "XX_stats = XX_stats.merge(user_entropy_test, on='user', how='left').merge(extreme_ratio_test, on='user', how='left').fillna(0)\n",
    "\n",
    "XX_stats['user_mean_rank'] = XX_stats['mean_rating'].rank(pct=True)\n",
    "\n",
    "# merge\n",
    "df_reg_test = df_reg_test.merge(XX_stats, on='user', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37815d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170162\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 672\n",
      "[LightGBM] [Info] Start training from score 0.506428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 MAE: 0.0646\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 672\n",
      "[LightGBM] [Info] Start training from score 0.506512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 MAE: 0.0679\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 672\n",
      "[LightGBM] [Info] Start training from score 0.506512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 MAE: 0.0655\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170165\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 672\n",
      "[LightGBM] [Info] Start training from score 0.506512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 MAE: 0.0657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 170196\n",
      "[LightGBM] [Info] Number of data points in the train set: 2880, number of used features: 672\n",
      "[LightGBM] [Info] Start training from score 0.506577\n",
      "Fold 5 MAE: 0.0666\n",
      "\n",
      "Mean MAE: 0.0661 ± 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruv/.local/share/mise/installs/python/3.12.11/lib/python3.12/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_data = df_reg_train.drop(columns=['user', 'label'])\n",
    "y_data = df_reg_train['label']\n",
    "X_data.columns = X_data.columns.astype(str)\n",
    "\n",
    "y_bins = pd.qcut(y_data, q=10, labels=False)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "xgb_params = dict(\n",
    "    n_estimators=3500,\n",
    "    learning_rate=0.008,\n",
    "    max_depth=5,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    eval_metric='mae'\n",
    ")\n",
    "\n",
    "lgb_params = dict(\n",
    "    n_estimators=3500,\n",
    "    learning_rate=0.008,\n",
    "    num_leaves=31,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    random_state=42,\n",
    "    objective='mae',\n",
    "    metric='mae'\n",
    ")\n",
    "\n",
    "mae_scores = []\n",
    "\n",
    "# --- Cross-validation ---\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X_data, y_bins)):\n",
    "    X_train, X_val = X_data.iloc[train_idx], X_data.iloc[val_idx]\n",
    "    y_train, y_val = y_data.iloc[train_idx], y_data.iloc[val_idx]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled   = scaler.transform(X_val)\n",
    "\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    lgb = LGBMRegressor(**lgb_params)\n",
    "\n",
    "    xgb.fit(X_train_scaled, y_train)\n",
    "    lgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred = (0.6 * xgb.predict(X_val_scaled)) + (0.4 * lgb.predict(X_val_scaled))\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    mae_scores.append(mae)\n",
    "    print(f\"Fold {i+1} MAE: {mae:.4f}\")\n",
    "\n",
    "print(f\"\\nMean MAE: {np.mean(mae_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
